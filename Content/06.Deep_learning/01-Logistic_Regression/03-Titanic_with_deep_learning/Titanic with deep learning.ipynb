{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic \n",
    "\n",
    "Take up the Titanic project again, and insert a deep-learning into it to see if you can improve your results!\n",
    "\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "![](https://plus.lesoir.be/sites/default/files/dpistyles_v2/ena_16_9_extra_big/2019/04/12/node_218060/26251893/public/2019/04/12/B9719141564Z.1_20190412142710_000+GO7DBN7S7.1-0.jpg?itok=UrOcJg8T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \\\n",
      "0            1         0       3  Braund, Mr. Owen Harris  male  22.0      1   \n",
      "\n",
      "   Parch     Ticket  Fare Cabin Embarked  \n",
      "0      0  A/5 21171  7.25   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "titanic_train = pd.read_csv('train.csv')\n",
    "print(titanic_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass              Name   Sex   Age  SibSp  Parch  Ticket  \\\n",
      "0          892       3  Kelly, Mr. James  male  34.5      0      0  330911   \n",
      "\n",
      "     Fare Cabin Embarked  \n",
      "0  7.8292   NaN        Q  \n"
     ]
    }
   ],
   "source": [
    "titanic_test = pd.read_csv('test.csv')\n",
    "print(titanic_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [titanic_train, titanic_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    data.drop(['Cabin', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    data['Title'] = data['Title'].map(title_mapping)\n",
    "    data['Title'] = data['Title'].fillna(0)\n",
    "    \n",
    "    data.drop(['Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set up the LabelEncoder object\n",
    "enc = LabelEncoder()\n",
    "for data in dataset:\n",
    "    # Apply the encoding to the \"Accessible\" column\n",
    "    data['Sex'] = enc.fit_transform(data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "for data in dataset:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = data[(data['Sex'] == i) & \\\n",
    "                                  (data['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            age_guess = guess_df.mean()\n",
    "\n",
    "            # round float number\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            data.loc[ (data.Age.isnull()) & (data.Sex == i) & (data.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    data['Age'] = data['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:    \n",
    "    data.loc[ data['Age'] <= 16, 'Age'] = 0\n",
    "    data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1\n",
    "    data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2\n",
    "    data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3\n",
    "    data.loc[ data['Age'] > 64, 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "for data in dataset:\n",
    "    data['IsAlone'] = 0\n",
    "    data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "   \n",
    "    data = data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    freq_port = data.Embarked.dropna().mode()[0]\n",
    "    data['Embarked'] = data['Embarked'].fillna(freq_port)\n",
    "    data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    data['Fare'].fillna(data['Fare'].dropna().median(), inplace=True)\n",
    "        \n",
    "    data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare']   = 2\n",
    "    data.loc[ data['Fare'] > 31, 'Fare'] = 3\n",
    "    data['Fare'] = data['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train = titanic_train.drop(\"Survived\", axis=1).values\n",
    "y_train = to_categorical(titanic_train[\"Survived\"])\n",
    "X_test  = titanic_test.values\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = X_train.shape[1]\n",
    "n_cats = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.6914\n",
      "Epoch 2/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7464\n",
      "Epoch 3/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7991\n",
      "Epoch 4/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8036\n",
      "Epoch 5/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8070\n",
      "Epoch 6/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8182\n",
      "Epoch 7/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8092\n",
      "Epoch 8/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8137\n",
      "Epoch 9/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8126\n",
      "Epoch 10/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8114\n",
      "Epoch 11/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8171\n",
      "Epoch 12/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8215\n",
      "Epoch 13/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8215\n",
      "Epoch 14/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8204\n",
      "Epoch 15/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8148\n",
      "Epoch 16/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8305\n",
      "Epoch 17/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8126\n",
      "Epoch 18/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8126\n",
      "Epoch 19/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8328\n",
      "Epoch 20/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8260\n",
      "Epoch 21/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8227\n",
      "Epoch 22/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8373\n",
      "Epoch 23/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8272\n",
      "Epoch 24/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8316\n",
      "Epoch 25/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8260\n",
      "Epoch 26/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8339\n",
      "Epoch 27/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8305\n",
      "Epoch 28/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8283\n",
      "Epoch 29/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8305\n",
      "Epoch 30/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8339\n",
      "Epoch 31/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8361\n",
      "Epoch 32/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8305\n",
      "Epoch 33/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8406\n",
      "Epoch 34/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8305\n",
      "Epoch 35/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8395\n",
      "Epoch 36/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8406\n",
      "Epoch 37/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8373\n",
      "Epoch 38/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8373\n",
      "Epoch 39/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8305\n",
      "Epoch 40/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8373\n",
      "Epoch 41/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8339\n",
      "Epoch 42/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8373\n",
      "Epoch 43/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8272\n",
      "Epoch 44/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8361\n",
      "Epoch 45/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8384\n",
      "Epoch 46/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8418\n",
      "Epoch 47/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8429\n",
      "Epoch 48/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8418\n",
      "Epoch 49/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8429\n",
      "Epoch 50/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8361\n",
      "Epoch 51/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8361\n",
      "Epoch 52/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8373\n",
      "Epoch 53/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8418\n",
      "Epoch 54/60\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8440\n",
      "Epoch 55/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8350\n",
      "Epoch 56/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8451\n",
      "Epoch 57/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8440\n",
      "Epoch 58/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8451\n",
      "Epoch 59/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8418\n",
      "Epoch 60/60\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa05cacc50>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(n_cats, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 0\n",
       "894                 0\n",
       "895                 0\n",
       "896                 1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predictions, index=titanic_test.PassengerId, columns=['survived'])\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./results7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
