{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Slide 1\n",
    "# Automatic data collection on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Slide 2\n",
    "Before we start to tackle some nice web pages (html), we will discover the xml language which is a good introduction to data web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML was created to facilitate data exchange between machines and software.\n",
    "\n",
    "XML is a language that is written using tags.\n",
    "\n",
    "XML is a W3C recommendation, so it is a technology with strict rules to follow.\n",
    "\n",
    "XML is intended to be understandable by everyone: people and machines alike.\n",
    "\n",
    "XML allows us to create our own vocabulary using a set of customizable rules and tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML is also compatible with the web so that data exchanges can be easily carried out over the Internet.\n",
    "\n",
    "XML is therefore standardized, simple, but above all extensible and configurable so that any type of data can be described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of an XML document, which we have saved as data.xml in the data directory\n",
    "\n",
    "Display its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<users>\n",
      "    <user data-id=\"101\">\n",
      "        <nom>Zorro</nom>\n",
      "        <metier>Danseur</metier>\n",
      "    </user>\n",
      "    <user data-id=\"102\">\n",
      "        <nom>Hulk</nom>\n",
      "        <metier>Footballeur</metier>\n",
      "    </user>\n",
      "    <user data-id=\"103\">\n",
      "        <nom>Zidane</nom>\n",
      "        <metier>Star</metier>\n",
      "    </user>\n",
      "    <user data-id=\"104\">\n",
      "        <nom>Beans</nom>\n",
      "        <metier>Epicier</metier>\n",
      "    </user>\n",
      "    <user data-id=\"105\">\n",
      "        <nom>Batman</nom>\n",
      "        <metier>Veterinaire</metier>\n",
      "    </user>\n",
      "    <user data-id=\"106\">\n",
      "        <nom>Spiderman</nom>\n",
      "        <metier>Veterinaire</metier>\n",
      "    </user>\n",
      "</users>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"../../04.File-handling/data/data.xml\", \"r\")\n",
    "print (file.read())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line indicates the encoding, we always stay in the UTF-8 encoding. Then we notice that the \"users\" tag has other \"user\" tags that themselves have their own tags. The data is hierarchized in a tree and each node provides information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a small script that displays all the user names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zorro\n",
      "Hulk\n",
      "Zidane\n",
      "Beans\n",
      "Batman\n",
      "Spiderman\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "# I define my source document\n",
    "tree = etree.parse(\"../../04.File-handling/data/data.xml\")\n",
    "# I look at my document and identify the tag path to get to the \"user\" information\n",
    "# Indeed, the information is in a name tag itself present in a user tag\n",
    "# it even presents itself in a users tag. This last tag is located at the root of the directory\n",
    "# so in tree.xpath(\"/users/user/name\") there are the tags associated with our search\n",
    "for user in tree.xpath(\"/users/user/nom\"):\n",
    "    # I want to display only the content (.text) of these tags /users/user/name\n",
    "    print(user.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zorro'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.xpath(\"/users/user/nom\")[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "# You can display the attributes of the tags that store this information\n",
    "tree = etree.parse(\"../../04.File-handling/data/data.xml\")\n",
    "for user in tree.xpath(\"/users/user\"):\n",
    "    print(user.get(\"data-id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can refine the display by proposing to display only users whose job is Veterinary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batman\n",
      "Spiderman\n"
     ]
    }
   ],
   "source": [
    "tree = etree.parse(\"../../04.File-handling/data/data.xml\")\n",
    "# Quel joli petit dictionnaire\n",
    "for user in tree.xpath(\"/users/user[metier='Veterinaire']/nom\"):\n",
    "    print(user.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data web scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw earlier how to parse XML, it is also possible to parse HTML and the tool that does the job best in my opinion is the BeautifulSoup librairy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a web page (for example becode.org) that you like in the data directory, and display its content (the xxx.html file)\n",
    "\n",
    "Put the content of this page in a variable, for example html_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML>\n",
      "\n",
      "<html lang=\"en\">\n",
      "\n",
      "\n",
      "\n",
      "<head>\n",
      "\n",
      "\t<title>BeCode.org for Friends</title>\n",
      "\n",
      "\t<meta charset=\"utf-8\" />\n",
      "\n",
      "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "\n",
      "\t<!--[if lte IE 8]><script src=\"assets/js/ie/html5shiv.js\"></script><![endif]-->\n",
      "\n",
      "\t<link rel=\"stylesheet\" href=\"assets/css/main.css\" />\n",
      "\n",
      "\t<!--[if lte IE 8]><link rel=\"stylesheet\" href=\"assets/css/ie8.css\" /><![endif]-->\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"../../04.File-handling/data/becode.html\", \"r\", encoding=\"utf8\")\n",
    "\n",
    "for _ in range(10):\n",
    "    html_doc=file.readline()\n",
    "    print(html_doc)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeCode.org\n"
     ]
    }
   ],
   "source": [
    "file = open(\"../../04.File-handling/data/becode.html\", \"r\", encoding=\"utf8\")\n",
    "html_doc = file.read()\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")\n",
    "# In my file (becode.org) by looking at this html script We can see that the main title is arranged in the h1 tag\n",
    "\n",
    "for p in soup.find_all('h1'):\n",
    "    # We only retrieve the content ==> .text\n",
    "    print (p.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with H2 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A school to address the skills gap in an inclusive way\n",
      "A Belgian coding school, powered by a methodology with a proven track record\n",
      "Realtime Stats\n",
      "Our story\n",
      "The team\n",
      "Our partners\n",
      "Board of directors\n",
      "Here's how you can make a difference.\n",
      "Goodies and Ready-To-Share Content\n"
     ]
    }
   ],
   "source": [
    "for p in soup.find_all('h2'):\n",
    "    # We only retrieve the content ==> .text\n",
    "    print (p.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, do the same with the \"p\" tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Our mission : Enabling tomorrow's digital talents to blossom. \n",
      "\t\t\t\t\t\tWe believe that education makes anything possible. \n",
      "\t\t\t\t\t\tSince 2017, BeCode has been offering free training courses for jobseekers to become web developers in partnership\n",
      "\t\t\t\t\t\twith Simplon.\n",
      "1 Hereâ€™s how you can help!\n",
      "2 Opportunities and talents currently remain untapped due to a skills gap: \n",
      "\t\t\t\t\tthe gap between what employers need and what job seekers are offering today.\n"
     ]
    }
   ],
   "source": [
    "for n, p in enumerate(soup.find_all('p')[:3]):\n",
    "    # We only retrieve the content ==> .text\n",
    "    print (n, p.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping via request HTTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP is a kind of language that will allow the client (you, through your browser for example) to communicate with a server connected to the network (the HTTP server installed on a site's server, for example Apache).\n",
    "\n",
    "Requests always go in pairs: the request (from the client) and the response (from the server).\n",
    "If this is not the case, it is because a problem has occurred at a point in the network.\n",
    "\n",
    "The syntax of the request (= client request) is always the same:\n",
    "- Command line (Command, URL, Protocol version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command is the method to use, it specifies the type of request, it can have the values :\n",
    "\n",
    "\n",
    "GET\n",
    "This is the most common way to request a resource. A GET request has no effect on the resource, it must be possible to repeat the request without effect.\n",
    "\n",
    "HEAD\n",
    "This method only asks for information about the resource, without asking for the resource itself.\n",
    "\n",
    "POST\n",
    "This method must be used when a request modifies the resource.\n",
    "\n",
    "OPTIONS\n",
    "This method allows you to obtain the communication options of a resource or the server in general.\n",
    "\n",
    "CONNECT\n",
    "This method allows you to use a proxy as a communication tunnel.\n",
    "\n",
    "TRACE\n",
    "This method asks the server to return what it has received, in order to test and diagnose the connection.\n",
    "\n",
    "PUT\n",
    "This method allows you to add a resource to the server.\n",
    "\n",
    "DELETE\n",
    "This method allows you to delete a resource from the server.\n",
    "\n",
    "I will only discuss the most common ones here: HEAD, GET and POST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it into practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.becode.org/about/ 200\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en-US\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "<link href=\"https://becode.org/wp/xmlrpc.php\" rel=\"pingback\"/>\n",
      "<script type=\"text/javascript\">\n",
      "\t\tdocument.documentElement.className = 'js';\n",
      "\t</script>\n",
      "<script>var et_site_url='https://becode.org/wp';var et_post_id='52';function et_core_page_resource_fallback(a,b){\"undefined\"===typeof b&&(b=a.sheet.cssRules&&0===a.sheet.cssRules.length);b&&(a.onerror=null,a.onload=null,a.href?a.href=et_site_url+\"/?et_core_page_resource=\"+a.id+et_post_id:a.src&&(a.src=et_site_url+\"/?et_core_page_resource=\"+a.id+et_post_id))}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Url of website\n",
    "url='https://www.becode.org/about/'\n",
    "# I send my HTTP request with a \"GET\" to the site server to identify in the url\n",
    "r = requests.get(url)\n",
    "# I display the requested url and the return of the server\n",
    "print(url, r.status_code)\n",
    "# I ask beautifulSoup to keep in a soup variable the web page to scrape (url) an html script\n",
    "soup = BeautifulSoup(r.content,'lxml')\n",
    "soup_list = str(soup).split('\\n')\n",
    "for i in soup_list[0:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have thus retrieved the information from the site without physically saving it in a file, only in a variable!\n",
    "\n",
    "Display the main title, the subtitles of and the paragraphs and their descriptions again to convince you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Passion for learning</h1>\n"
     ]
    }
   ],
   "source": [
    "for h1 in soup.find_all('h1'):\n",
    "    print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>Our mission</h2>\n",
      "<h2>BeCode Pedagogical Framework</h2>\n",
      "<h2>Education is in Our Blood</h2>\n",
      "<h2 class=\"et_pb_module_header\">Meet the team</h2>\n",
      "<h2>Our campuses</h2>\n",
      "<h2>A thousand different stories</h2>\n",
      "<h2>Partners</h2>\n",
      "<h2>Public partners</h2>\n",
      "<h2>Private partners</h2>\n",
      "<h2>Educational partners</h2>\n"
     ]
    }
   ],
   "source": [
    "for h2 in soup.find_all('h2'):\n",
    "    print(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><span style=\"font-weight: 400;\">At BeCode, we are dreamers. We believe we can change the world, make it a better place. A more equal place, where everyone has access to a proper education, whatever their background.</span></p>\n",
      "<p><b><i>Therefore we</i></b> <b><i>provide qualitative, competitive and inclusive coding bootcamps, accessible to all</i></b><span style=\"font-weight: 400;\">.</span></p>\n",
      "<p>Our mission is to <strong>grow todayâ€™s talented â€“ and especially vulnerable â€“ professionals into tomorrowâ€™s best developers</strong>.</p>\n",
      "<p>With the current shortage in the market, employers are more motivated than ever to opt for a diversified recruitment strategy, focusing on skills rather than diplomas. In addition, these professions offer well-paying, interesting and long-term career opportunities for all those entering the industry today.</p>\n",
      "<p>We therefore want to help <strong>bridge the gap between motivated job seekers and the employer market</strong>, by using the shortage of digital skills as a lever for a more inclusive workforce.</p>\n"
     ]
    }
   ],
   "source": [
    "for p in soup.find_all('p')[:5]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
